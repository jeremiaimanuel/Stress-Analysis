{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeje_\\anaconda3\\envs\\mne-label\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import signal as sg\n",
    "from mne.preprocessing import read_ica\n",
    "from mne_icalabel import label_components\n",
    "import asrpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Folder Name - NEED MODIFICATION DEPENDING ON THE SUBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"20231019_B68_stroop5mins/20231019_B68_stroop5mins_0001.vhdr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define save directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name, file_name = os.path.split(fpath)\n",
    "folder_epoch_asr = \"hep_asr\"\n",
    "folder_epoch_eog = \"hep_eog\"\n",
    "folder_epoch_cfa = \"hep_eog_cfa\"\n",
    "folder_filtered_asr = \"filtered_data_asr\"\n",
    "folder_filtered_eog = \"filtered_data_ica_eog\"\n",
    "folder_filtered_cfa = \"filtered_data_ica_eog_cfa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from 20231019_B68_stroop5mins/20231019_B68_stroop5mins_0001.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 958599  =      0.000 ...   958.599 secs...\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1']\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"D:/EEG RESEARCH DATA\"\n",
    "os.chdir(directory_path)\n",
    "raw = mne.io.read_raw_brainvision(fpath)\n",
    "raw.load_data()\n",
    "\n",
    "# Reconstruct the original events from our Raw object\n",
    "events, event_ids = mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>October 19, 2023  10:08:22 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>64 EEG, 2 EOG, 1 ECG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>vEOG, hEOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>ECG</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1000.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.02 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>20231019_B68_stroop5mins_0001.eeg</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:15:59 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawBrainVision | 20231019_B68_stroop5mins_0001.eeg, 67 x 958600 (958.6 s), ~490.1 MB, data loaded>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "raw.set_channel_types({'ECG':'ecg'})\n",
    "raw.set_channel_types({'vEOG':'eog'})\n",
    "raw.set_channel_types({'hEOG':'eog'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>October 19, 2023  10:08:22 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>67 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>64 EEG, 2 EOG, 1 ECG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>vEOG, hEOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>ECG</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1000.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.02 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>20231019_B68_stroop5mins_0001.eeg</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:15:59 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawBrainVision | 20231019_B68_stroop5mins_0001.eeg, 67 x 958600 (958.6 s), ~490.1 MB, data loaded>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.set_montage(montage)\n",
    "#fig = raw.plot_sensors(show_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment Grouping - NEED MODIFICATION DEPENDING ON THE SUBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1000\n",
    "\n",
    "trg0 = events[9,0] #Experiment Begin \n",
    "trg1 = events[10,0] #Task Begin\n",
    "trg2 = events[-2,0] #Task End\n",
    "trg3 = events[-1,0] #Experiment End\n",
    "\n",
    "tmin = trg0/fs\n",
    "tmax = trg3/fs\n",
    "\n",
    "############################### Segment Grouping for EEG ###############################\n",
    "#Segment in Samples\n",
    "eeg_seg1 = trg1 - trg0\n",
    "eeg_seg2 = trg2 - trg0\n",
    "eeg_seg3 = trg3 - trg0\n",
    "\n",
    "#Segment in ms\n",
    "eeg_newseg1 = eeg_seg1/fs\n",
    "eeg_newseg2 = eeg_seg2/fs\n",
    "eeg_newseg3 = eeg_seg3/fs\n",
    "############################### Segment Grouping for EEG ###############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pan_tompkins_qrs():\n",
    "    def bpf(self,x):\n",
    "        \n",
    "        y_filtered = None\n",
    "        \n",
    "        # x = np.squeeze(x)\n",
    "        #Results will be delayed 16 Samples\n",
    "        y = x.copy()\n",
    "\n",
    "        #Low Pass Filter\n",
    "        #y(n) = 2y(n-1) - y(n-2) + x(n) - 2x(n-6) + x(n-12)\n",
    "        for n in range(len(x)):\n",
    "            y[n] = x[n]\n",
    "\n",
    "            if (n >= 1):\n",
    "                y[n] += 2*y[n-1]\n",
    "            if (n >= 2):\n",
    "                y[n] -= y[n-2]\n",
    "            if (n >= 6):\n",
    "                y[n] -= 2*x[n-6]\n",
    "            if (n >= 12):\n",
    "                y[n] += x[n-12]\n",
    "        \n",
    "        y_filtered = y.copy()\n",
    "\n",
    "        #High Pass Filter\n",
    "        #y(n) = 32x(n-16) - y(n-1) - x(n) + x(n-32)\n",
    "        for n in range(len(x)):\n",
    "            y_filtered[n] = -1*y[n]\n",
    "\n",
    "            if (n >= 1):\n",
    "                y_filtered[n] -= y_filtered[n-1]\n",
    "            if (n >= 16):\n",
    "                y_filtered[n] += 32*y[n-16]\n",
    "            if(n >= 32):\n",
    "                y_filtered[n] += y[n-32]\n",
    "        \n",
    "        #Normalization\n",
    "        max_val = max(max(y_filtered), -min(y_filtered))\n",
    "        y_filtered = y_filtered/max_val\n",
    "\n",
    "        return y_filtered\n",
    "    \n",
    "    def derivative(self,x,fs):\n",
    "        \n",
    "        #Results will be delayed for 2 samples\n",
    "        y_derived = x.copy()\n",
    "        \n",
    "        #Derivative Filter\n",
    "        #y(n) = [-x(n-2) - 2x(n-1) + 2x(n+1) + x(n+2)]/8\n",
    "        for n in range(len(x)):\n",
    "            y_derived[n] = 0\n",
    "\n",
    "            if (n >= 1):\n",
    "                y_derived[n] -= 2*x[n-1]\n",
    "            if (n >= 2):\n",
    "                y_derived[n] -= x[n-2]\n",
    "            \n",
    "            ###For this part [2x(n+1) + x(n+2)]###\n",
    "            if (n >= 2 and n <= len(x)-2):\n",
    "                y_derived[n] += 2*x[n+1]\n",
    "            if (n >= 2 and n<= len(x)-3):\n",
    "                y_derived[n] += x[n+2]\n",
    "            ###For this part [2x(n+1) + x(n+2)]###\n",
    "\n",
    "            ###In trasnfer function times 1/T, change to times fs###\n",
    "            y_derived[n] = (y_derived[n]*fs)/8\n",
    "            ###In trasnfer function times 1/T, change to times fs###\n",
    "        \n",
    "        return y_derived\n",
    "    \n",
    "    def squaring(self,x):\n",
    "        \n",
    "        y_squared = x.copy()\n",
    "\n",
    "        for n in range(len(x)):\n",
    "            y_squared[n] = x[n]**2\n",
    "\n",
    "        return y_squared\n",
    "    \n",
    "    def moving_window_integration(self,x,fs):\n",
    "        # Initialize result and window size for integration\n",
    "        y = x.copy()\n",
    "        win_size = round(0.150 * fs)\n",
    "        sum = 0\n",
    "\n",
    "        # Calculate the sum for the first N terms\n",
    "        for j in range(win_size):\n",
    "            sum += x[j]/win_size\n",
    "            y[j] = sum\n",
    "        \n",
    "        # Apply the moving window integration using the equation given\n",
    "        for n in range(win_size,len(x)):  \n",
    "            sum += x[n]/win_size\n",
    "            sum -= x[n-win_size]/win_size\n",
    "            y[n] = sum\n",
    "\n",
    "        return y\n",
    "\n",
    "    def solve(self,x,fs):\n",
    "\n",
    "        # Convert the input signal into numpy array\n",
    "        input_signal = x.copy()\n",
    "\n",
    "        # Bandpass Filter\n",
    "        global bpass\n",
    "        bpass = self.bpf(input_signal)\n",
    "\n",
    "        # Derivative Function\n",
    "        global der\n",
    "        der = self.derivative(bpass,fs)\n",
    "\n",
    "        # Squaring Function\n",
    "        global sqr\n",
    "        sqr = self.squaring(der)\n",
    "\n",
    "        # Moving Window Integration Function\n",
    "        global mwin\n",
    "        mwin = self.moving_window_integration(sqr,fs)\n",
    "\n",
    "        return mwin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class heart_rate():\n",
    "    def __init__(self,x,fs):\n",
    "        #Initialize Variables\n",
    "        self.RR1, self.RR2, self.probable_peaks, self.r_locs, self.peaks, self.result = ([] for i in range(6))\n",
    "        self.SPKI, self.NPKI, self.Threshold_I1, self.Threshold_I2, self.SPKF, self.NPKF, self.Threshold_F1, self.Threshold_F2 = (0 for i in range(8))\n",
    "\n",
    "        self.T_wave = False\n",
    "        self.m_win = mwin\n",
    "        self.b_pass = bpass\n",
    "        self.fs = fs\n",
    "        # self.signal = np.squeeze(x)\n",
    "        self.signal = x\n",
    "        self.win_150ms = round(0.15*self.fs)\n",
    "\n",
    "        self.RR_Low_Limit = 0\n",
    "        self.RR_High_Limit = 0\n",
    "        self.RR_Missed_Limit = 0\n",
    "        self.RR_Average1 = 0\n",
    "\n",
    "    def approx_peak(self):\n",
    "        slopes = sg.fftconvolve(self.m_win, np.full((25,),1)/25, mode='same')\n",
    "\n",
    "        # for i in range(round(0.5*self.fs) + 1,len(slopes)-1):\n",
    "        for i in range(0,len(slopes)-1):\n",
    "            if (slopes[i] > slopes[i-1]) and (slopes[i+1] <slopes[i]):\n",
    "                self.peaks.append(i)\n",
    "\n",
    "    def adjust_rr_interval(self, ind):\n",
    "        self.RR1 = np.diff(self.peaks[max(0,ind - 8) : ind + 1])/self.fs  \n",
    "\n",
    "        # Calculating RR Averages\n",
    "        self.RR_Average1 = np.mean(self.RR1)\n",
    "        RR_Average2 = self.RR_Average1\n",
    "        \n",
    "        # Finding the eight most recent RR intervals lying between RR Low Limit and RR High Limit  \n",
    "        if (ind >= 8):\n",
    "            for i in range(0, 8):\n",
    "                if (self.RR_Low_Limit < self.RR1[i] < self.RR_High_Limit): \n",
    "                    self.RR2.append(self.RR1[i])\n",
    "\n",
    "                    if (len(self.RR2) > 8):\n",
    "                        self.RR2.remove(self.RR2[0])\n",
    "                        RR_Average2 = np.mean(self.RR2)    \n",
    "\n",
    "        # Adjusting the RR Low Limit and RR High Limit\n",
    "        if (len(self.RR2) > 7 or ind < 8):\n",
    "            self.RR_Low_Limit = 0.92 * RR_Average2        \n",
    "            self.RR_High_Limit = 1.16 * RR_Average2\n",
    "            self.RR_Missed_Limit = 1.66 * RR_Average2\n",
    "    \n",
    "    def searchback(self, peak_val, RRn, sb_win):\n",
    "        # Check if the most recent RR interval is greater than the RR Missed Limit\n",
    "        if (RRn > self.RR_Missed_Limit):\n",
    "            # Initialize a window to searchback  \n",
    "            win_rr = self.m_win[peak_val - sb_win + 1 : peak_val + 1] \n",
    "\n",
    "            # Find the x locations inside the window having y values greater than Threshold I1             \n",
    "            coord = np.asarray(win_rr > self.Threshold_I1).nonzero()[0]\n",
    "\n",
    "            # Find the x location of the max peak value in the search window\n",
    "            if (len(coord) > 0):\n",
    "                for pos in coord:\n",
    "                    if (win_rr[pos] == max(win_rr[coord])):\n",
    "                        x_max = pos\n",
    "                        break\n",
    "            else:\n",
    "                x_max = None\n",
    "    \n",
    "            # If the max peak value is found\n",
    "            if (x_max is not None):   \n",
    "                # Update the thresholds corresponding to moving window integration\n",
    "                self.SPKI = 0.25 * self.m_win[x_max] + 0.75 * self.SPKI                         \n",
    "                self.Threshold_I1 = self.NPKI + 0.25 * (self.SPKI - self.NPKI)\n",
    "                self.Threshold_I2 = 0.5 * self.Threshold_I1         \n",
    "\n",
    "                # Initialize a window to searchback \n",
    "                win_rr = self.b_pass[x_max - self.win_150ms: min(len(self.b_pass) -1, x_max)]  \n",
    "\n",
    "                # Find the x locations inside the window having y values greater than Threshold F1                   \n",
    "                coord = np.asarray(win_rr > self.Threshold_F1).nonzero()[0]\n",
    "\n",
    "                # Find the x location of the max peak value in the search window\n",
    "                if (len(coord) > 0):\n",
    "                    for pos in coord:\n",
    "                        if (win_rr[pos] == max(win_rr[coord])):\n",
    "                            r_max = pos\n",
    "                            break\n",
    "                else:\n",
    "                    r_max = None\n",
    "\n",
    "                # If the max peak value is found\n",
    "                if (r_max is not None):\n",
    "                # Update the thresholds corresponding to bandpass filter\n",
    "                    if self.b_pass[r_max] > self.Threshold_F2:                                                        \n",
    "                        self.SPKF = 0.25 * self.b_pass[r_max] + 0.75 * self.SPKF                            \n",
    "                        self.Threshold_F1 = self.NPKF + 0.25 * (self.SPKF - self.NPKF)\n",
    "                        self.Threshold_F2 = 0.5 * self.Threshold_F1      \n",
    "\n",
    "                        # Append the probable R peak location                      \n",
    "                        self.r_locs.append(r_max)\n",
    "\n",
    "    def find_t_wave(self,peak_val,RRn,ind,prev_ind):\n",
    "        '''\n",
    "        T Wave Identification\n",
    "        :param peak_val: peak location in consideration\n",
    "        :param RRn: the most recent RR interval\n",
    "        :param ind: current index in peaks array\n",
    "        :param prev_ind: previous index in peaks array\n",
    "        '''\n",
    "\n",
    "        if (self.m_win[peak_val] >= self.Threshold_I1): \n",
    "            if (ind > 0 and 0.20 < RRn < 0.36):\n",
    "                # Find the slope of current and last waveform detected        \n",
    "                curr_slope = max(np.diff(self.m_win[peak_val - round(self.win_150ms/2) : peak_val + 1]))\n",
    "                last_slope = max(np.diff(self.m_win[self.peaks[prev_ind] - round(self.win_150ms/2) : self.peaks[prev_ind] + 1]))\n",
    "            \n",
    "                # If current waveform slope is less than half of last waveform slope\n",
    "                if (curr_slope < 0.5*last_slope):  \n",
    "                    # T Wave is found and update noise threshold                      \n",
    "                    self.T_wave = True                             \n",
    "                    self.NPKI = 0.125 * self.m_win[peak_val] + 0.875 * self.NPKI \n",
    "\n",
    "            if (not self.T_wave):\n",
    "                # T Wave is not found and update signal thresholds\n",
    "                if (self.probable_peaks[ind] > self.Threshold_F1):   \n",
    "                    self.SPKI = 0.125 * self.m_win[peak_val]  + 0.875 * self.SPKI                                         \n",
    "                    self.SPKF = 0.125 * self.b_pass[ind] + 0.875 * self.SPKF \n",
    "\n",
    "                    # Append the probable R peak location\n",
    "                    self.r_locs.append(self.probable_peaks[ind])  \n",
    "\n",
    "                else:\n",
    "                    self.SPKI = 0.125 * self.m_win[peak_val]  + 0.875 * self.SPKI\n",
    "                    self.NPKF = 0.125 * self.b_pass[ind] + 0.875 * self.NPKF                   \n",
    "\n",
    "        # Update noise thresholds\n",
    "        elif (self.m_win[peak_val] < self.Threshold_I1) or (self.Threshold_I1 < self.m_win[peak_val] < self.Threshold_I2):\n",
    "            self.NPKI = 0.125 * self.m_win[peak_val]  + 0.875 * self.NPKI  \n",
    "            self.NPKF = 0.125 * self.b_pass[ind] + 0.875 * self.NPKF\n",
    "\n",
    "\n",
    "    def adjust_thresholds(self,peak_val,ind):\n",
    "        '''\n",
    "        Adjust Noise and Signal Thresholds During Learning Phase\n",
    "        :param peak_val: peak location in consideration\n",
    "        :param ind: current index in peaks array\n",
    "        '''\n",
    "\n",
    "        if (self.m_win[peak_val] >= self.Threshold_I1): \n",
    "            # Update signal threshold\n",
    "            self.SPKI = 0.125 * self.m_win[peak_val]  + 0.875 * self.SPKI\n",
    "\n",
    "            if (self.probable_peaks[ind] > self.Threshold_F1):                                            \n",
    "                self.SPKF = 0.125 * self.b_pass[ind] + 0.875 * self.SPKF \n",
    "\n",
    "                # Append the probable R peak location\n",
    "                self.r_locs.append(self.probable_peaks[ind])  \n",
    "\n",
    "            else:\n",
    "                # Update noise threshold\n",
    "                self.NPKF = 0.125 * self.b_pass[ind] + 0.875 * self.NPKF                                    \n",
    "            \n",
    "        # Update noise thresholds    \n",
    "        elif (self.m_win[peak_val] < self.Threshold_I2) or (self.Threshold_I2 < self.m_win[peak_val] < self.Threshold_I1):\n",
    "            self.NPKI = 0.125 * self.m_win[peak_val]  + 0.875 * self.NPKI  \n",
    "            self.NPKF = 0.125 * self.b_pass[ind] + 0.875 * self.NPKF\n",
    "\n",
    "\n",
    "    def update_thresholds(self):\n",
    "        '''\n",
    "        Update Noise and Signal Thresholds for next iteration\n",
    "        '''\n",
    "\n",
    "        self.Threshold_I1 = self.NPKI + 0.25 * (self.SPKI - self.NPKI)\n",
    "        self.Threshold_F1 = self.NPKF + 0.25 * (self.SPKF - self.NPKF)\n",
    "        self.Threshold_I2 = 0.5 * self.Threshold_I1 \n",
    "        self.Threshold_F2 = 0.5 * self.Threshold_F1\n",
    "        self.T_wave = False \n",
    "\n",
    "\n",
    "    def ecg_searchback(self):\n",
    "        '''\n",
    "        Searchback in ECG signal to increase efficiency\n",
    "        '''\n",
    "\n",
    "        # Filter the unique R peak locations\n",
    "        self.r_locs = np.unique(np.array(self.r_locs).astype(int))\n",
    "        \n",
    "        # Initialize a window to searchback\n",
    "        win_200ms = round(0.2*self.fs)\n",
    "    \n",
    "    \n",
    "    \n",
    "        for r_val in self.r_locs:\n",
    "            \n",
    "            coord = np.arange(r_val - win_200ms, min(len(self.signal), r_val + win_200ms + 1), 1)\n",
    "            \n",
    "            # Find the x location of the max peak value\n",
    "            if (len(coord) > 0):\n",
    "                for pos in coord:               \n",
    "                    if (self.signal[pos] == max(self.signal[coord])):\n",
    "                        x_max = pos\n",
    "                        break\n",
    "            else:\n",
    "                x_max = None\n",
    "\n",
    "            # Append the peak location\n",
    "            if (x_max is not None):   \n",
    "                self.result.append(x_max)\n",
    "\n",
    "\n",
    "    def find_r_peaks(self):\n",
    "        '''\n",
    "        R Peak Detection\n",
    "        '''\n",
    "\n",
    "        # Find approximate peak locations\n",
    "        self.approx_peak()\n",
    "\n",
    "        # Iterate over possible peak locations\n",
    "        for ind in range(len(self.peaks)):\n",
    "\n",
    "            # Initialize the search window for peak detection\n",
    "            peak_val = self.peaks[ind]\n",
    "            win_300ms = np.arange(max(0, self.peaks[ind] - self.win_150ms), min(self.peaks[ind] + self.win_150ms, len(self.b_pass)-1), 1)\n",
    "            max_val = max(self.b_pass[win_300ms], default = 0)\n",
    "\n",
    "            # Find the x location of the max peak value\n",
    "            if (max_val != 0):        \n",
    "                x_coord = np.asarray(self.b_pass == max_val).nonzero()\n",
    "                self.probable_peaks.append(x_coord[0][0])\n",
    "                \n",
    "            if (ind < len(self.probable_peaks) and ind != 0):\n",
    "                # Adjust RR interval and limits\n",
    "                self.adjust_rr_interval(ind)\n",
    "                \n",
    "                # Adjust thresholds in case of irregular beats\n",
    "                if (self.RR_Average1 < self.RR_Low_Limit or self.RR_Average1 > self.RR_Missed_Limit): \n",
    "                    self.Threshold_I1 /= 2\n",
    "                    self.Threshold_F1 /= 2\n",
    "\n",
    "                RRn = self.RR1[-1]\n",
    "\n",
    "                # Searchback\n",
    "                self.searchback(peak_val,RRn,round(RRn*self.fs))\n",
    "\n",
    "                # T Wave Identification\n",
    "                self.find_t_wave(peak_val,RRn,ind,ind-1)\n",
    "\n",
    "            else:\n",
    "                # Adjust threholds\n",
    "                self.adjust_thresholds(peak_val,ind)\n",
    "\n",
    "            # Update threholds for next iteration\n",
    "            self.update_thresholds()\n",
    "\n",
    "        # Searchback in ECG signal \n",
    "        self.ecg_searchback()\n",
    "\n",
    "        return np.unique(self.result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eeg_ica(signal = raw, tmin = tmin, tmax = tmax, fpath = fpath):\n",
    "    raw_temp = signal.copy().crop(tmin = tmin, tmax = tmax) #make a copy\n",
    "    raw_temp.load_data()\n",
    "\n",
    "    ica = read_ica(fname=fpath.replace(\".vhdr\", \"-ica.fif\"))\n",
    "\n",
    "    filt_raw = raw_temp.load_data().copy().filter(l_freq=1.0, h_freq=None)\n",
    "\n",
    "    ic_labels = label_components(filt_raw, ica, method=\"iclabel\")\n",
    "    print(ic_labels[\"labels\"])\n",
    "\n",
    "    labels = ic_labels[\"labels\"]\n",
    "    eog_indices = [idx for idx, label in enumerate(labels) if label in [\"eye blink\"]]\n",
    "    eog_cfa_indices = [idx for idx, label in enumerate(labels) if label in [\"eye blink\",\"heart beat\"]]\n",
    "\n",
    "    if \"heart beat\" not in labels:\n",
    "        print(\"No CFA Detected in %s\" % file_name)\n",
    "\n",
    "    ica.exclude = eog_indices\n",
    "    reconst_raw_eog = raw_temp.copy()\n",
    "    ica.apply(reconst_raw_eog)\n",
    "\n",
    "    ica.exclude = eog_cfa_indices\n",
    "    reconst_raw_cfa = raw_temp.copy()\n",
    "    ica.apply(reconst_raw_cfa)\n",
    "    \n",
    "    reconst_raw_eog.save(os.path.join(folder_filtered_eog,file_name.replace(\".vhdr\", \"-ica.fif\")), overwrite=True)\n",
    "    reconst_raw_cfa.save(os.path.join(folder_filtered_cfa,file_name.replace(\".vhdr\", \"-ica.fif\")), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eeg_asr(signal=raw,tmin=tmin,tmax=tmax,t_seg1 = eeg_newseg1,t_seg2 = eeg_newseg2,tseg3 = eeg_newseg3, cutoff= 5):\n",
    "    raw_temp = signal.copy().crop(tmin = tmin, tmax = tmax).pick_types(eeg=True, ecg=False, eog=False).filter(l_freq=1.0, h_freq=40, picks = ['eeg'])#make a copy\n",
    "#######################################################\n",
    "    raw_asr_first = raw_temp.copy().crop(tmin=0, tmax=t_seg1)\n",
    "\n",
    "    asr = asrpy.ASR(sfreq=raw_asr_first.info[\"sfreq\"], cutoff=cutoff)\n",
    "    asr.fit(raw_asr_first)\n",
    "    raw_asr_first = asr.transform(raw_asr_first)\n",
    "#######################################################\n",
    "    raw_asr_stress = raw_temp.copy().crop(tmin=t_seg1, tmax=t_seg2)\n",
    "\n",
    "    asr = asrpy.ASR(sfreq=raw_asr_stress.info[\"sfreq\"], cutoff=cutoff)\n",
    "    asr.fit(raw_asr_stress)\n",
    "    raw_asr_stress = asr.transform(raw_asr_stress)\n",
    "#######################################################\n",
    "    raw_asr_second = raw_temp.copy().crop(tmin=t_seg2, tmax=tseg3)\n",
    "\n",
    "    asr = asrpy.ASR(sfreq=raw_asr_second.info[\"sfreq\"], cutoff=cutoff)\n",
    "    asr.fit(raw_asr_second)\n",
    "    raw_asr_second = asr.transform(raw_asr_second)\n",
    "  #######################################################  \n",
    "    raw_asr = [raw_asr_first, raw_asr_stress, raw_asr_second]\n",
    "    mne.concatenate_raws(raw_asr)\n",
    "    raw_asr.save(os.path.join(folder_filtered_asr,file_name.replace(\".vhdr\", \"-ica.fif\")), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG Data - ICA Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 20231019_B68_stroop5mins/20231019_B68_stroop5mins_0001-ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "C:\\Users\\jeje_\\AppData\\Local\\Temp\\ipykernel_15936\\2517524544.py:21: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(filt_raw, ica, method=\"iclabel\")\n",
      "C:\\Users\\jeje_\\AppData\\Local\\Temp\\ipykernel_15936\\2517524544.py:21: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
      "  ic_labels = label_components(filt_raw, ica, method=\"iclabel\")\n",
      "C:\\Users\\jeje_\\AppData\\Local\\Temp\\ipykernel_15936\\2517524544.py:21: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  ic_labels = label_components(filt_raw, ica, method=\"iclabel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eye blink', 'other', 'brain', 'eye blink', 'brain', 'brain', 'brain', 'brain', 'brain', 'muscle artifact', 'other', 'muscle artifact', 'muscle artifact', 'other', 'brain', 'muscle artifact', 'other', 'muscle artifact', 'other', 'muscle artifact', 'muscle artifact', 'channel noise', 'muscle artifact', 'muscle artifact', 'other', 'muscle artifact', 'muscle artifact', 'muscle artifact', 'muscle artifact', 'muscle artifact', 'muscle artifact', 'channel noise']\n",
      "No CFA Detected in 20231019_B68_stroop5mins_0001.vhdr\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (32 components)\n",
      "    Zeroing out 2 ICA components\n",
      "    Projecting back using 64 PCA components\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (32 components)\n",
      "    Zeroing out 2 ICA components\n",
      "    Projecting back using 64 PCA components\n",
      "Writing D:\\EEG RESEARCH DATA\\filtered_data_ica_eog\\20231019_B68_stroop5mins_0001-ica.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeje_\\AppData\\Local\\Temp\\ipykernel_15936\\2517524544.py:39: RuntimeWarning: This filename (D:\\EEG RESEARCH DATA\\filtered_data_ica_eog\\20231019_B68_stroop5mins_0001-ica.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  reconst_raw_eog.save(os.path.join(folder_filtered_eog,file_name.replace(\".vhdr\", \"-ica.fif\")), overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing D:\\EEG RESEARCH DATA\\filtered_data_ica_eog\\20231019_B68_stroop5mins_0001-ica.fif\n",
      "[done]\n",
      "Writing D:\\EEG RESEARCH DATA\\filtered_data_ica_eog_cfa\\20231019_B68_stroop5mins_0001-ica.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeje_\\AppData\\Local\\Temp\\ipykernel_15936\\2517524544.py:40: RuntimeWarning: This filename (D:\\EEG RESEARCH DATA\\filtered_data_ica_eog_cfa\\20231019_B68_stroop5mins_0001-ica.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  reconst_raw_cfa.save(os.path.join(folder_filtered_cfa,file_name.replace(\".vhdr\", \"-ica.fif\")), overwrite=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing D:\\EEG RESEARCH DATA\\filtered_data_ica_eog_cfa\\20231019_B68_stroop5mins_0001-ica.fif\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "extract_eeg_ica(raw,tmin,tmax,fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG Data - ASR Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    }
   ],
   "source": [
    "extract_eeg_asr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERP Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ecg = raw.copy().pick_types(eeg=False, eog=False, ecg=True).crop(tmin = tmin, tmax = tmax) #make a copy\n",
    "\n",
    "mne_ecg,_ = raw_ecg[:]\n",
    "mne_ecg = np.squeeze(-mne_ecg)\n",
    "\n",
    "b, a = sg.butter(2, [0.5, 150], 'bandpass', output= 'ba', fs=fs)\n",
    "mne_ecg = sg.filtfilt(b,a,mne_ecg)\n",
    "\n",
    "QRS_detector = pan_tompkins_qrs()\n",
    "output = QRS_detector.solve(mne_ecg, fs)\n",
    "\n",
    "# Find the R peak locations\n",
    "hr = heart_rate(mne_ecg,fs)\n",
    "result = hr.find_r_peaks()\n",
    "result = np.array(result)\n",
    "\n",
    "# Clip the x locations less than 0 (Learning Phase)\n",
    "result = result[result > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pan-Tompkins Events for Epoch Time Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_peak_onset = []\n",
    "for i in range(len(result)):\n",
    "    ons_idx = int(fs*tmin)+result[i]\n",
    "    r_peak_onset.append(ons_idx)\n",
    "\n",
    "pan_tompkins_events = np.zeros((len(r_peak_onset), 3), dtype=int)\n",
    "\n",
    "pan_tompkins_events[:, 0] = r_peak_onset\n",
    "pan_tompkins_events[:, 1] = 0 \n",
    "pan_tompkins_events[:, 2] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_tmin = -0.2\n",
    "epoch_tmax = 0.6\n",
    "baseline = (None,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOG Derived Epoch Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_filt_raw = reconst_raw_eog.load_data().copy().filter(l_freq=1.0, h_freq=40, picks = ['eeg'])\n",
    "\n",
    "eog_filt_firstrest = eog_filt_raw.copy().crop(tmin = 0, tmax = eeg_newseg1)\n",
    "eog_filt_stress = eog_filt_raw.copy().crop(tmin = eeg_newseg1, tmax = eeg_newseg2)\n",
    "eog_filt_secondrest = eog_filt_raw.copy().crop(tmin = eeg_newseg2)\n",
    "\n",
    "eog_first_epoch = mne.Epochs(eog_filt_firstrest,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n",
    "eog_stress_epoch = mne.Epochs(eog_filt_stress,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n",
    "eog_second_epoch = mne.Epochs(eog_filt_secondrest,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EOG Evoked Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eog_first_epoch = mne.Epochs(eog_filt_firstrest,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n",
    "# eog_first_evoked = eog_first_epoch.average()\n",
    "# eog_first_evoked.plot_joint()\n",
    "\n",
    "# hep_data_first_rest = eog_first_evoked.get_data()\n",
    "# hep_data_first_rest = hep_data_first_rest.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eog_stress_epoch = mne.Epochs(eog_filt_stress,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n",
    "# eog_stress_evoked = eog_stress_epoch.average()\n",
    "# eog_stress_evoked.plot_joint()\n",
    "\n",
    "# hep_data_stress = eog_stress_evoked.get_data()\n",
    "# hep_data_stress = hep_data_stress.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eog_second_epoch = mne.Epochs(eog_filt_secondrest,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n",
    "# eog_second_evoked = eog_second_epoch.average()\n",
    "# eog_second_evoked.plot_joint()\n",
    "\n",
    "# hep_data_second_rest = eog_second_evoked.get_data()\n",
    "# hep_data_second_rest = hep_data_second_rest.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evokeds = dict(first_rest = eog_first_evoked,stress = eog_stress_evoked,second_rest = eog_second_evoked)\n",
    "# mne.viz.plot_compare_evokeds(evokeds,title = 'HEP [All Channel]',combine=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### CFA Derived Epoch Exctraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfa_filt_raw = reconst_raw_cfa.load_data().copy().filter(l_freq=1.0, h_freq=40, picks = ['eeg'])\n",
    "\n",
    "cfa_filt_firstrest = cfa_filt_raw.copy().crop(tmin = 0, tmax = eeg_newseg1)\n",
    "cfa_filt_stress = cfa_filt_raw.copy().crop(tmin = eeg_newseg1, tmax = eeg_newseg2)\n",
    "cfa_filt_secondrest = cfa_filt_raw.copy().crop(tmin = eeg_newseg2)\n",
    "\n",
    "cfa_first_epoch = mne.Epochs(cfa_filt_firstrest,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n",
    "cfa_stress_epoch = mne.Epochs(cfa_filt_stress,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n",
    "cfa_second_epoch = mne.Epochs(cfa_filt_secondrest,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CFA Evoked Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfa_first_epoch = mne.Epochs(cfa_filt_firstrest,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n",
    "# cfa_first_evoked = cfa_first_epoch.average()\n",
    "# cfa_first_evoked.plot_joint()\n",
    "\n",
    "# hep_data_first_rest = cfa_first_evoked.get_data()\n",
    "# hep_data_first_rest = hep_data_first_rest.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfa_stress_epoch = mne.Epochs(cfa_filt_stress,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n",
    "# cfa_stress_evoked = cfa_stress_epoch.average()\n",
    "# cfa_stress_evoked.plot_joint()\n",
    "\n",
    "# hep_data_stress = cfa_stress_evoked.get_data()\n",
    "# hep_data_stress = hep_data_stress.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfa_second_epoch = mne.Epochs(cfa_filt_secondrest,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n",
    "# cfa_second_evoked = cfa_second_epoch.average()\n",
    "# cfa_second_evoked.plot_joint()\n",
    "\n",
    "# hep_data_second_rest = cfa_second_evoked.get_data()\n",
    "# hep_data_second_rest = hep_data_second_rest.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evokeds = dict(first_rest = cfa_first_evoked,stress = cfa_stress_evoked,second_rest = cfa_second_evoked)\n",
    "# mne.viz.plot_compare_evokeds(evokeds,title = 'HEP [All Channel]',combine=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASR Epoch Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_epoch = mne.Epochs(raw_asr,events = pan_tompkins_events, tmin= epoch_tmin, tmax = epoch_tmax, baseline = baseline, picks = ['eeg'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Filtered EEG Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconst_raw_eog.save(os.path.join(folder_filtered_eog,file_name.replace(\".vhdr\", \"-ica.fif\")), overwrite=True)\n",
    "reconst_raw_cfa.save(os.path.join(folder_filtered_cfa,file_name.replace(\".vhdr\", \"-ica.fif\")), overwrite=True)\n",
    "raw_asr.save(os.path.join(folder_filtered_asr,file_name.replace(\".vhdr\", \"-ica.fif\")), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract HEP Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_first_epoch.save(os.path.join(folder_epoch_eog,file_name.replace(\".vhdr\", \"-first-epo.fif\")), overwrite=True)\n",
    "eog_stress_epoch.save(os.path.join(folder_epoch_eog,file_name.replace(\".vhdr\", \"-stress-epo.fif\")), overwrite='True')\n",
    "eog_second_epoch.save(os.path.join(folder_epoch_eog,file_name.replace(\".vhdr\", \"-second-epo.fif\")), overwrite='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfa_first_epoch.save(os.path.join(folder_epoch_cfa,file_name.replace(\".vhdr\", \"-first-epo.fif\")), overwrite='True')\n",
    "cfa_stress_epoch.save(os.path.join(folder_epoch_cfa,file_name.replace(\".vhdr\", \"-stress-epo.fif\")), overwrite='True')\n",
    "cfa_second_epoch.save(os.path.join(folder_epoch_cfa,file_name.replace(\".vhdr\", \"-second-epo.fif\")), overwrite='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG Data - ICA Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_temp = raw.copy().crop(tmin = tmin, tmax = tmax) #make a copy\n",
    "raw_temp.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = read_ica(fname=fpath.replace(\".vhdr\", \"-ica.fif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_raw = raw_temp.load_data().copy().filter(l_freq=1.0, h_freq=None)\n",
    "\n",
    "ic_labels = label_components(filt_raw, ica, method=\"iclabel\")\n",
    "print(ic_labels[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ic_labels[\"labels\"]\n",
    "eog_indices = [idx for idx, label in enumerate(labels) if label in [\"eye blink\"]]\n",
    "eog_cfa_indices = [idx for idx, label in enumerate(labels) if label in [\"eye blink\",\"heart beat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ica.exclude = [0, 3, 18, 19, 10, 11, 15,26,27, 29, 24, 30, 9, 23,31]\n",
    "# ica.exclude = [0, 3, 17, 19, 15, 29, 30]\n",
    "ica.exclude = eog_indices\n",
    "reconst_raw_eog = raw_temp.copy()\n",
    "ica.apply(reconst_raw_eog)\n",
    "\n",
    "ica.exclude = eog_cfa_indices\n",
    "reconst_raw_cfa = raw_temp.copy()\n",
    "ica.apply(reconst_raw_cfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG Data - ASR Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_asr = raw_temp.copy().pick_types(eeg=True, ecg=False, eog=False).crop(tmin=0, tmax=300).filter(l_freq=1.0, h_freq=40, picks = ['eeg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_asr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m asr \u001b[38;5;241m=\u001b[39m asrpy\u001b[38;5;241m.\u001b[39mASR(sfreq\u001b[38;5;241m=\u001b[39m\u001b[43mraw_asr\u001b[49m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfreq\u001b[39m\u001b[38;5;124m\"\u001b[39m], cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;32m      2\u001b[0m asr\u001b[38;5;241m.\u001b[39mfit(raw_asr)\n",
      "\u001b[0;32m      3\u001b[0m raw_asr \u001b[38;5;241m=\u001b[39m asr\u001b[38;5;241m.\u001b[39mtransform(raw_asr)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw_asr' is not defined"
     ]
    }
   ],
   "source": [
    "asr = asrpy.ASR(sfreq=raw_asr.info[\"sfreq\"], cutoff=5)\n",
    "asr.fit(raw_asr)\n",
    "raw_asr = asr.transform(raw_asr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne-label",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
